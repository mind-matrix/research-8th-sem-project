{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Positional Encoding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNDhZIjBPXGH1u2ebvLAFFv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mind-matrix/research-8th-sem-project/blob/main/Positional_Encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O78MQq7WS9RE"
      },
      "source": [
        "import numpy as np\r\n",
        "from math import sin, cos"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpwad0Q1NnMv"
      },
      "source": [
        "def encoding_vector(t, d=2):\r\n",
        "  p = []\r\n",
        "  for i in range(0, d):\r\n",
        "    k = i//2\r\n",
        "    w_k = 1/(10000**(2*k/d))\r\n",
        "    p_t = sin(w_k * t) if i % 2 == 0 else cos(w_k * t)\r\n",
        "    p.append(p_t)\r\n",
        "  return np.array(p)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09-OjTEGXkTh"
      },
      "source": [
        "def positional_encodings(size, d=2):\r\n",
        "  evs = []\r\n",
        "  for t in range(size):\r\n",
        "    evs.append(encoding_vector(t, d=d))\r\n",
        "  return np.array(evs)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl5mwuo5YTm5",
        "outputId": "08bc6657-63a2-4483-f639-987ff2c11d09"
      },
      "source": [
        "num_tokens = 10 # Example: calculate encoding for sentence with 10 tokens\r\n",
        "encodings = positional_encodings(num_tokens)\r\n",
        "print(encodings)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.          1.        ]\n",
            " [ 0.84147098  0.54030231]\n",
            " [ 0.90929743 -0.41614684]\n",
            " [ 0.14112001 -0.9899925 ]\n",
            " [-0.7568025  -0.65364362]\n",
            " [-0.95892427  0.28366219]\n",
            " [-0.2794155   0.96017029]\n",
            " [ 0.6569866   0.75390225]\n",
            " [ 0.98935825 -0.14550003]\n",
            " [ 0.41211849 -0.91113026]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsnIp9x4Yq8f",
        "outputId": "6d7f55f3-f2e5-4897-9bb9-659dc9a9eb1d"
      },
      "source": [
        "encodings = positional_encodings(num_tokens, d=5) # Adding more dimensions to the encoding vectors\r\n",
        "print(encodings)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
            "   0.00000000e+00]\n",
            " [ 8.41470985e-01  5.40302306e-01  2.51162229e-02  9.99684538e-01\n",
            "   6.30957303e-04]\n",
            " [ 9.09297427e-01 -4.16146837e-01  5.02165994e-02  9.98738351e-01\n",
            "   1.26191435e-03]\n",
            " [ 1.41120008e-01 -9.89992497e-01  7.52852930e-02  9.97162035e-01\n",
            "   1.89287090e-03]\n",
            " [-7.56802495e-01 -6.53643621e-01  1.00306487e-01  9.94956586e-01\n",
            "   2.52382670e-03]\n",
            " [-9.58924275e-01  2.83662185e-01  1.25264396e-01  9.92123395e-01\n",
            "   3.15478149e-03]\n",
            " [-2.79415498e-01  9.60170287e-01  1.50143272e-01  9.88664249e-01\n",
            "   3.78573502e-03]\n",
            " [ 6.56986599e-01  7.53902254e-01  1.74927419e-01  9.84581331e-01\n",
            "   4.41668705e-03]\n",
            " [ 9.89358247e-01 -1.45500034e-01  1.99601200e-01  9.79877217e-01\n",
            "   5.04763732e-03]\n",
            " [ 4.12118485e-01 -9.11130262e-01  2.24149048e-01  9.74554875e-01\n",
            "   5.67858558e-03]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}